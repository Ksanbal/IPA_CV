{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "elKZAac0IAlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a1429955-d015-4290-bdbe-5c6ef36204ec"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1J2XfmAIFod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "7adfdbfb-472c-423b-a3b1-ea376c9e37e9"
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "# (28, 28, 1)\n",
        "input_img = Input(shape=(28, 28, 1)) \n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "# (Batch, 28,  28, 16)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# (Batch, 14, 14, 16)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "# (Batch, 14, 14, 8)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# (Batch, 7, 7, 8)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "# (Batch, 7, 7, 8)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# (Batch, 7, 7, 8) -> # (Batch, 8, 8, 8) -> # (Batch, 4, 4, 8)\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "# (Batch, 4, 4, 8)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "# (Batch, 8, 8, 8)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "# (Batch, 8, 8, 16)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "# (Batch, 16, 16, 16)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "# (Batch, 14, 14, 32)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "# (Batch, 28, 28, 32)\n",
        "\n",
        "decoded = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
        "# (Batch, 28, 28, 1)\n",
        "# (28, 28, 1)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 8)           584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 1)         33        \n",
            "=================================================================\n",
            "Total params: 8,329\n",
            "Trainable params: 8,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj7pNdSvIHZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40fb3b93-da9f-4e5a-e50e-01f240473565"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.2183 - val_loss: 0.1779\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1659 - val_loss: 0.1583\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1553 - val_loss: 0.1529\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1499 - val_loss: 0.1472\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1464 - val_loss: 0.1458\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1439 - val_loss: 0.1385\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1420 - val_loss: 0.1383\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1405 - val_loss: 0.1404\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1392 - val_loss: 0.1373\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1381 - val_loss: 0.1374\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1374 - val_loss: 0.1360\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1367 - val_loss: 0.1372\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1360 - val_loss: 0.1343\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1354 - val_loss: 0.1328\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1347 - val_loss: 0.1314\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1342 - val_loss: 0.1366\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1336 - val_loss: 0.1322\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1333 - val_loss: 0.1315\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1329 - val_loss: 0.1318\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1327 - val_loss: 0.1316\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1323 - val_loss: 0.1346\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1319 - val_loss: 0.1301\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.1316 - val_loss: 0.1298\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.1313 - val_loss: 0.1313\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1312 - val_loss: 0.1303\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1310 - val_loss: 0.1311\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1307 - val_loss: 0.1302\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1306 - val_loss: 0.1294\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1303 - val_loss: 0.1293\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1300 - val_loss: 0.1281\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1295 - val_loss: 0.1295\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1295 - val_loss: 0.1294\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1294 - val_loss: 0.1317\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1293 - val_loss: 0.1311\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.1291 - val_loss: 0.1282\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1289 - val_loss: 0.1273\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1289 - val_loss: 0.1272\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1288 - val_loss: 0.1273\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1287 - val_loss: 0.1279\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1285 - val_loss: 0.1273\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1284 - val_loss: 0.1282\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1283 - val_loss: 0.1270\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1281 - val_loss: 0.1284\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1280 - val_loss: 0.1273\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1280 - val_loss: 0.1261\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1276 - val_loss: 0.1280\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1276 - val_loss: 0.1265\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1275 - val_loss: 0.1250\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1273 - val_loss: 0.1283\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1272 - val_loss: 0.1273\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1271 - val_loss: 0.1255\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1272 - val_loss: 0.1254\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1271 - val_loss: 0.1270\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1268 - val_loss: 0.1258\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1268 - val_loss: 0.1256\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1269 - val_loss: 0.1264\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1267 - val_loss: 0.1263\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1267 - val_loss: 0.1246\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1265 - val_loss: 0.1250\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1265 - val_loss: 0.1246\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1265 - val_loss: 0.1270\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1264 - val_loss: 0.1256\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1263 - val_loss: 0.1265\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1263 - val_loss: 0.1261\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1262 - val_loss: 0.1266\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1261 - val_loss: 0.1244\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1260 - val_loss: 0.1249\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1261 - val_loss: 0.1243\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1260 - val_loss: 0.1258\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1259 - val_loss: 0.1267\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1259 - val_loss: 0.1255\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1258 - val_loss: 0.1251\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1257 - val_loss: 0.1245\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1257 - val_loss: 0.1257\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1257 - val_loss: 0.1242\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1256 - val_loss: 0.1239\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1255 - val_loss: 0.1254\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.1255 - val_loss: 0.1247\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1253 - val_loss: 0.1262\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1252 - val_loss: 0.1243\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1252 - val_loss: 0.1238\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1252 - val_loss: 0.1234\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1252 - val_loss: 0.1236\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1251 - val_loss: 0.1244\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1252 - val_loss: 0.1249\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1251 - val_loss: 0.1247\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1251 - val_loss: 0.1252\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1251 - val_loss: 0.1231\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1249 - val_loss: 0.1232\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1250 - val_loss: 0.1237\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1250 - val_loss: 0.1234\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1249 - val_loss: 0.1250\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1248 - val_loss: 0.1231\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1247 - val_loss: 0.1250\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1248 - val_loss: 0.1243\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1248 - val_loss: 0.1236\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1247 - val_loss: 0.1238\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1246 - val_loss: 0.1256\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1246 - val_loss: 0.1250\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1247 - val_loss: 0.1237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f20af423240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJbNhcWhIMtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-My4z1VI6ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "da522e3e-5237-4899-90d8-20fdb9c4f400"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCTZgppsJo_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}